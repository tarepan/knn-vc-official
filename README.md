<div align="center">

# kNN-VC <!-- omit in toc -->
[![ColabBadge]][notebook]
[![PaperBadge]][paper]  

</div>

Clone of official kNN-VC, simple kNN-based voice conversion.  

<!-- Auto-generated by "Markdown All in One" extension -->
- [Demo](#demo)
- [Usage](#usage)
  - [Install](#install)
  - [Inference](#inference)
    - [Checkpoints](#checkpoints)
  - [Train](#train)
- [Results](#results)
- [Official info](#official-info)
- [References](#references)

![kNN-VC method](./knn-vc.png)

## Demo
[official demo][demo page].  

## Usage
### Install

```bash
# Python >=3.10
pip install "torch>=2" "torchaudio>=2" numpy
```

No kNN-VC install is needed. `torch.hub` handle everythingðŸ˜‰

### Inference

```python
import torch, torchaudio

src_wav_path = '<path to arbitrary 16kHz waveform>.wav'
ref_wav_paths = ['<path to arbitrary 16kHz waveform from target speaker>.wav', '<path to 2nd utterance from target speaker>.wav', ...]

knn_vc = torch.hub.load('tarepan/knn-vc-official', 'knn_vc', prematched=True, trust_repo=True, pretrained=True)

query_seq = knn_vc.get_features(src_wav_path)
matching_set = knn_vc.get_matching_set(ref_wav_paths)

out_wav = knn_vc.match(query_seq, matching_set, topk=4)
# out_wav is (T,) tensor converted 16kHz output wav using k=4 for kNN.
```

Options:

- `knn_vc.match`
  - `topk`: int - Top K
- `torch.hub.load`
  - `prematched`: bool - Whether to use prematched model or non-prematched model


#### Checkpoints

Under the releases tab of this repo we provide three checkpoints:

- Encoder: WavLM (taken from [official WavLM](https://github.com/microsoft/unilm/tree/master/wavlm))
- Vocoder 1: HiFiGAN w/ raw-WavLM-L6
- Vocoder 2: HiFiGAN w/ prematched-WavLM-L6

For the HiFiGAN models we provide both the generator inference checkpoint and full training checkpoint with optimizer states.  
For performance, see the paper.  


### Train

Install `librosa`, `tensorboard`, `matplotlib`, `fastprogress` and `scipy`.

1. **Precompute WavLM features of the vocoder dataset**: we provide a utility for this for the LibriSpeech dataset in `prematch_dataset.py`:

    ```bash
    usage: prematch_dataset.py [-h] --librispeech_path LIBRISPEECH_PATH
                            [--seed SEED] --out_path OUT_PATH [--device DEVICE]
                            [--topk TOPK] [--matching_layer MATCHING_LAYER]
                            [--synthesis_layer SYNTHESIS_LAYER] [--prematch]
                            [--resume]
    ```

    e.g. (prematch):
    `python prematch_dataset.py --librispeech_path /path/to/librispeech/root --out_path /path/where/you/want/outputs/to/go --topk 4 --matching_layer 6 --synthesis_layer 6 --prematch`

2. **Train HiFiGAN**: until 2.5M steps

    ```bash
    python -m hifigan.train --audio_root_path /path/to/librispeech/root/ --feature_root_path /path/to/the/output/of/previous/step/ --input_training_file data_splits/wavlm-hifigan-train.csv --input_validation_file data_splits/wavlm-hifigan-valid.csv --checkpoint_path /path/where/you/want/to/save/checkpoint --fp16 False --config hifigan/config_v1_wavlm.json --stdout_interval 25 --training_epochs 1800 --fine_tuning
    ```


## Results
### Sample <!-- omit in toc -->
[Demo](#demo)

### Performance <!-- omit in toc -->
- training
  - xx [iter/sec] @ NVIDIA A100 on paperspace gradient Notebook (ConvTF32+/AMP+)
  - take about xx days for whole training
- inference
  - z.z [sec/sample] @ xx


## Official info
- HuBERT-Base work well ([issue#10](https://github.com/bshall/knn-vc/issues/10))


## References
### Original paper <!-- omit in toc -->
[![PaperBadge]][paper]  
<!-- Generated with the tool -> https://arxiv2bibtex.org/?q=2305.18975&format=bibtex -->
```bibtex
@misc{2305.18975,
Author = {Matthew Baas and Benjamin van Niekerk and Herman Kamper},
Title = {Voice Conversion With Just Nearest Neighbors},
Year = {2023},
Eprint = {arXiv:2305.18975},
}
```

### Acknowlegements <!-- omit in toc -->
- [Official kNN-VC](https://github.com/bshall/knn-vc)
- [HiFiGAN](https://github.com/jik876/hifi-gan)
- [WavLM](https://github.com/microsoft/unilm/tree/master/wavlm)


[ColabBadge]:https://colab.research.google.com/assets/colab-badge.svg

[paper]:https://arxiv.org/abs/2305.18975
[PaperBadge]:https://img.shields.io/badge/paper-arxiv.2305.18975-B31B1B.svg
[notebook]:https://colab.research.google.com/github/tarepan/knn-vc-official/blob/main/knnvc.ipynb
[demo page]:https://bshall.github.io/knn-vc/
